
# Teledrop 파일 입출력 아키텍처 심층 분석

이 문서는 `teledrop` 백엔드가 파일, 특히 대용량 파일을 어떻게 효율적이고 안정적으로 처리하는지에 대한 아키텍처를 심층적으로 설명합니다.

## 1. 전체 아키텍처 개요

`teledrop`의 파일 업로드 처리는 다음과 같은 계층화된 아키텍처를 따릅니다.

1.  **Router Layer (`routers/api/drop.py`)**: FastAPI의 `APIRouter`를 사용하여 HTTP 요청을 수신하고, `UploadFile` 객체와 폼 데이터를 파싱하여 다음 계층으로 전달합니다.
2.  **Handler Layer (`handlers/drop/create.py`)**: 실제 비즈니스 로직을 수행합니다. 파일 해시 계산, `slug` 유효성 검사, 데이터베이스 레코드 생성 등 "무엇을" 할지 결정합니다.
3.  **Storage Layer (`infrastructure/storage/`)**: `StorageInterface`라는 추상화된 인터페이스를 통해 "어떻게" 파일을 저장할지 결정합니다. 현재 구현체인 `LocalStorage`는 로컬 디스크에 파일을 저장합니다.

이러한 계층 분리는 코드의 유지보수성, 테스트 용이성, 그리고 향후 다른 스토리지(예: S3)로의 확장성을 보장합니다.

## 2. 핵심 원리: 비동기 스트리밍

`teledrop`은 대용량 파일을 처리하기 위해 **비동기 스트리밍(Asynchronous Streaming)** 방식을 채택했습니다.

-   **메모리 효율성**: 10GB 파일을 업로드하더라도, 파일 전체를 메모리에 로드하지 않습니다. 대신, 파일을 작은 **청크(chunk)** 단위로 나누어 순차적으로 처리합니다. 이 덕분에 서버의 메모리 사용량은 파일 크기와 무관하게 거의 일정하게 유지되어, 여러 사용자의 동시 대용량 업로드에도 안정적으로 동작합니다.
-   **동시성 극대화**: FastAPI의 비동기(`async/await`) 모델을 활용하여, 파일 I/O(네트워크 수신, 디스크 쓰기)를 기다리는 동안 다른 요청을 처리할 수 있습니다. 이는 서버 자원 활용률을 극대화하고 높은 처리량을 달성하는 핵심입니다.

## 3. `UploadFile`과 `SpooledTemporaryFile`의 내부 동작

`teledrop`의 안정적인 스트리밍은 FastAPI(내부적으로는 Starlette)의 `UploadFile` 객체와 파이썬의 `tempfile.SpooledTemporaryFile` 덕분에 가능합니다.

1.  **`max_size` 임계점**: `UploadFile`은 내부적으로 약 **1MB**의 `max_size` 임계값을 가집니다.
2.  **메모리 모드 (파일 크기 < 1MB)**: 업로드된 파일 데이터는 우선 메모리 버퍼에 저장됩니다. 이 경우, 파일 I/O는 매우 빠르게 처리됩니다.
3.  **디스크 롤오버 (파일 크기 > 1MB)**: 데이터 크기가 `max_size`를 초과하는 순간, `UploadFile`은 **자동으로 디스크 모드로 전환**됩니다.
    -   지금까지 메모리에 있던 모든 데이터가 디스크의 **임시 파일**로 쓰여집니다.
    -   이후 들어오는 모든 데이터는 메모리를 거치지 않고 즉시 이 임시 파일에 추가됩니다.

이 "롤오버" 메커니즘 덕분에, 애플리케이션은 대용량 파일로 인해 메모리가 고갈될 위험 없이 안정적으로 파일을 수신할 수 있습니다.

## 4. 임시 파일 I/O와 페이지 캐시 최적화

`max_size`를 초과하는 파일은 다음과 같은 흐름을 거칩니다.

`네트워크 → 임시 파일 쓰기 → 임시 파일 읽기 → 최종 파일 쓰기`

표면적으로는 디스크 I/O가 두 번 발생하여 비효율적으로 보일 수 있습니다. 하지만 실제로는 운영체제(OS)의 **페이지 캐시(Page Cache)** 덕분에 이 오버헤드는 거의 없습니다.

-   **페이지 캐시**: OS는 디스크 I/O 성능 향상을 위해 RAM의 일부를 캐시로 사용합니다.
-   **최적화 동작**:
    1.  `teledrop`이 임시 파일에 데이터를 쓸 때, 해당 데이터는 OS의 페이지 캐시(RAM)에 저장될 확률이 높습니다.
    2.  직후에 `teledrop`이 그 임시 파일을 다시 읽을 때, OS는 물리 디스크가 아닌 **페이지 캐시에서 직접 데이터를 읽어** 전달합니다.

결과적으로, 코드 상의 "디스크 읽기/쓰기"는 실제로는 "메모리 읽기/쓰기"처럼 동작하여 성능 저하가 미미합니다. 이 방식은 약간의 오버헤드를 감수하는 대신, **메모리 안정성**과 **명확한 아키텍처 분리**라는 큰 이점을 제공하는 표준적인 엔지니어링 패턴입니다.

## 5. 경쟁 조건 및 데이터 무결성

`teledrop`은 동시성 환경에서도 데이터의 무결성을 보장하기 위한 여러 방어 장치를 갖추고 있습니다.

-   **파일 쓰기 경쟁 조건 방지**:
    -   파일을 저장할 경로는 `uuid.uuid4()`를 통해 생성된 **고유한 이름**을 사용합니다.
    -   따라서 두 개의 동시 요청은 절대로 같은 파일에 동시에 쓰려고 시도하지 않으므로, 파일 덮어쓰기와 관련된 경쟁 조건은 원천적으로 발생하지 않습니다.

-   **`slug` 생성 경쟁 조건 방어**:
    -   "Check-Then-Act" 패턴에서 발생할 수 있는 `slug` 중복 문제는 데이터베이스 테이블의 `slug` 컬럼에 설정된 **`UNIQUE` 제약 조건**을 통해 최후 방어선에서 처리됩니다. 중복 삽입 시도는 DB 레벨에서 거부되어 데이터 무결성을 보장합니다.

-   **보상 트랜잭션**:
    -   파일 저장은 성공했으나 DB 쓰기에 실패한 경우, **보상 트랜잭션**이 실행되어 이미 저장된 파일을 디스크에서 삭제합니다.
    -   이를 통해 "DB에는 없는데 파일만 존재하는" 고아(orphan) 데이터가 발생하는 것을 방지하고 시스템의 일관성을 유지합니다.

## 6. 결론

`teledrop`의 파일 입출력 시스템은 단순히 파일을 저장하는 것을 넘어, 현대적인 웹 애플리케이션이 갖춰야 할 **메모리 효율성, 높은 동시 처리 능력, 시스템 안정성, 데이터 무결성, 그리고 미래를 위한 확장성**을 모두 고려한 견고하고 정교한 아키텍처의 결과물입니다.
